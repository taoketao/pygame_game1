AI logic schema

In order to facilitate a variety of kinds of game object entities and a 
substantial variety of subkinds, each of which needs to interact either
procedurally, dynamically, or intelligently and reuse components highly,
a thoughtful schema for managing behavior has been devised.

Base entities: identified so far are the following distinct entities:
    human-controlled Player, ai pokemon, npc player, pokemon move, 
    character move, world sprite, dynamic environment objects.
Varieties: most distinctively, ai pokemon, their moves, and character moves
    have a large variety and interactivity such that hand-programming
    should be kept to a strict minimum.

Scheme for doing:
    let human Players, ai Pokemon, and npc players be Agents; let pokemon
    or character moves, sprites, and objects be Effects; and let the 
    broader shared world be represented with a single Game Manager.
    Then maintain:

    The Game Manager can read or write any Agent or Effect, as well as
        maintain external information about them. Any object can access
        informaiton from the Game Manager (which it well-maintains), but
        writes must be processed through specific access methods. 
    Agent cruxes have a unique Logic, a unique Belt, and a reference to the 
        Game Manager. The Agent can Read/Write the Belt or Logic, the 
        Belt and Logic can only read the Agent.
    Logics maintain (Internal)States, which it can read/write. Logics also
        maintain ActionPickers(APs).
    States are only written by Logics, and do not write (instead, Logic
        methods would need to be invoked to alter a State). They are intended
        to maintain information used for picking actions by an arbitrary AP.
    ActionPickers maintain subsets of other APs and components in Belts and 
        organize them as a decision node. This object decomposes decision 
        processes for input handling, event sequencing, and intelligent choice.
        ActionPickers read States: they're the `target audience' for States.
        ActionPickers encode a bite of logical decision-making, be it a 
        sequence of events, a conditional event, a parameterized sequence of
        APs, a 6-choose-3 situation, etc.
        APs have a reference to their specified Belt, and importantly, may
        contain additional APs internally.
    Belts hold many Actions, Items, Pkmn_prefabs, Sensors, and other fields 
        not maintained by States (such as special effects like Burn). 
    Actions are low-level objects that have the following attributes:
        - a viability flag (v-flag) that is T, F, or U. For any new frame, 
            this flag is set to U, and ActionPickers can request that this 
            Action determine its viability. After calling this function,
            this flag reads either T or F. These flags can also be indirectly
            altered by ActionPicker activity; example: if an action is ongoing
            and currently `running', an ActionPicker can automatically flip
            the flag to T.
        - a list of sensors required to perform this action. If an Agent lacks
            the Sensors in their Belt, the action results in F. Ex: a 'smart' 
            pokemon will attempt to find out the type of their opponent before
            using a typed move. These sensors are what the ActionPicker 
            engages, if this option is being considered.
        - an executable function. This function can be called arbitrarily to 
            actually, programmatically do this action after it has been chosen.
        Other components that Belts hold besides Actions are not yet specified,
        but likely will operate in similar ways: eg, *use* Item or *apply* 
        Burn damage.
    Moves are similar to agents, but have smaller complexity. Instead of having
        the full suite of a Logic, a Belt, a State, an AP, and Actions, Moves
        have: a single ActionPicker and a Belt. (This root AP can have 
        component APs if it wishes.) The reasoning is explained below:
    The core difference between Moves and Agents is persistence. Moves are 
        meant to be temporary, such as a glittering sprite, but we want to also
        endow it with the ability to logically act on its own. However, they
        are meant to be simple enough to warrant a maximal offloading of burden
        onto the target. That is, an 'egg bomb' move has an animation script,
        a window of time when it damages, perhaps a area-of-effect with 
        different damage based on distance, a vulnerability of being shot out
        of the air before it lands and rendered useless, and (essentially) an
        eventual termination regardless of activity. While this is complicated,
        it can all be maintained in a single ActionPicker line of logic, and
        any alterations that it would 'receive' would not have a long-lasting
        effect, since it is due to kill soon anyways; and the pokemon that 
        blasted it out of the sky can, in theory, easily maintain that it 
        successfully defended itself from the Move as the Move can say it it
        has been rendered ineffective. Alternatively considered, a Move can 
        maintain any state variables easily in memory in the AP object.
        Functionally, perhaps the main difference is that while Move-Agent and
        Agent-Agent interactions are common, Move-Move interactions should be
        minimal and hence the extra baggage of a Logic and State is not worth.
            On the contrary, Agents must last a long time, and changes done
        to them scale exponentially in possibilities and can have long-lasting
        effects. To this end, a true Logic system is engaged. Besides just 
        having a dedicated Logic manager and State object, the Logic object
        provides an interface for other entities, such as Moves or Agents,
        to affect this object. This is achieved through message passing,
        where anything can pass messages to an object (especially with Actions'
        executable functions! and perhaps even exclusively.) By maintaining
        that Logics receive messages and process them ('read the inbox'), a
        confidence in complex interactions can be upheld.
    In reality, it might very well make sense to add (lightweight) Logics and
        States to Moves. For that reason, Logics and States are being developed
        such that slim variants can be added.


--------------------------------------------------------------------------------


Implementation:

Agent A makes Logic AL, which makes State A(L)S
A makes Belt AB(AL)
AB makes Actions AB1,AB2,AB3
AL observes these Actions and makes ALAP(AS,AB1,AB3)->ALAP(AS,AB2,AB3)
Each Action has executables.


State manages hairy conditioning


ActionPicker is a subclass instance of Action, a special kind of action designed
    to cue other actions and maintain intermediate state information.

Workflow:
1. Entities reset their Actions with reset() calls and prepare for new frame.
2. Entities react based on information in their inbox as updating states.
3. Entities are given license to pick their actions, which may be restricted 
    based on states. Sensing and decisions happen here.
4. Entities carry out their chosen actions AFTER all decisions have been made.


Action pickers (or actions), if they return EVAL_T on the decision, then they 
must maintain information needed to Execute internally.

For both Moves and Agents:  (1) involves walking down ActionPicker and Action 
trees and reset values. Any persistent information should be stored in the
Agent's State or in specific ActionPickers.  Additionally, the Game Manager
is safe to update itself.
For Agents:  (2) invokes Logic to process inbox information, updating State.
For Moves:   (2) does nothing: inherently cannot intake messages.
For both Agents and Moves, 
For both Moves and Agents:  (3) cues the Entity to decide what action to take,
    and take it. Note that here, the order of activity only matters if global 
    fields are being altered; such updates should be buffered.

    Reactions go first -- that is,

    Active actions go first


todo:   - convert Player action into separated Motion and Set_Img actions,
    where the ActionPicker does: ALL{if_button{throw/catch}else{} AND SEQ[move->change_img]}
    - behavior tree BT framework. Our leaf nodes, Action objects, are highly 
      self-referential and combine the aspects of both BT's conditions and actions.
      This is done mainly for effective (high-frequency) turn-based activity
  Node types: priority, sequence, parallel; one-off issues with Running means they 
    could be reasonably done away with

States have several kinds of data to bank: 
    - one of world info relevant to this entity
    - one for each ActionPicker, for their own reference: as State so they can
        be shared and/or read
    - one for internal state flags, etc
  Schema:
    - dictionary AP_Alloc of Who -> Key -> Value 
    - dictionary of Sensor -> Result for (shared) global reference: sense()
        functions first query this table.
    - dictionary of other internal state variables. This is the likely place
        to maintain "Running"



AP types:
Sequential, Pick, identity.  Manually check running.
Make CondAP as a convenience of SequentialAP. (If, IfElse, IfElif)
  
Given a collection/mathematical set of actions, can have AP Nodes:
  - Priority: return EVAL_T on the first positive result of a collection. 
  - Sequential: return EVAL_T if all the objects happen.
        Sequential subsumes All-In-Collection.
        Partial-Sequential can be made to accept if n / n+m are successful.
  - Random: randomize the order of the actions for querying
  - DoAll, DoAny, ReturnAll, ReturnAny: boolean operations. DoAll and 
      ReturnAny are inefficient because they check every one.
  - MemSequential, MemPriority: prioritize currently-active actions first
  - Not: return EVAL_T if EVAL_F, etc
  - Pushdown: return whatever its component returns, but store its results
    in the State as a Pushdown Automata
  - Conditional (ie, If X do Y). Also variants Switch, IfElse, Try-Catch, etc.
  - LoopN or LoopWhile: run its component, but write to State information
    that enables looping.
  - Assert: return EVAL_ERR if not EVAL_T

Each Action and AP maintains its own data in the State, and interactions are
supported if desired.

Required attributes:
    - uniq_id as Who key in State. A method for accessing this safely.
    - a list of sensor keys that this A/AP requires. Some Sensors can preload
        information (flag them?), and this can be turned on if the Actions
        are accessed every iteration. But also there's no need for this...?
        Yeah, especially with Debugging, this'll get in the way. On-the-fly it is.
    - three core methods: find_viability, implement, reset/reload.
    - Access to component actions, for tree-building etc.


Example: 
In this example, lowerCamelCase indicate primitive Actions and UpperCamelCase
indicate custom-composite ActionPickers. 

    Player's root ActionPicker:
        DoAll(
            Sequential(
                isPlayerActionable()
                Cond( isPlayerReadyFor[Primary]Action() AND isMouseDown() ?, 
                      do ThrowPokeball(), else -- ),
               )
            Sequential(
                isPlayerMobile() // ie, not in a cutscene? Else, raise 
                playerMotion()   // <- this line out of the Sequential.
               )
        )
    and AP playerMotion is:
        Sequential(
            Try( Seq ( RandAll/ReturnAny(
                             PushDownUp(), PushDownDown(), 
                             PushDownRight(), PushDownLeft()
                         ),
                       SetCycleCounter[++]() 
                     )
                 catch: Stand()  )
            doAction()
            setNextPlayerImage()
        )
    where PushDown[dir]() is:
        Cond ( is[dir]ActionIndicated() AND is[dir]Valid()?
              do pushDownMotions_add[dir]( 
                  pdt.pushdown( atom motion[dir]() ) )
              ) else do pushDownMotions_remove_if_present[dir]()
        )
    Stand(): setCycleCounter[0]()   // Initialized pushdown stack [MotionStand()]
    doAction(): 
        Try (motion[pushDownTop](), catch motionStand())
        
    setNextPlayerImage():
        set_img[cycle_counter, direction]


Example basic-Pkmn-activity:
Rationale: first process receptive effects, apply damage, etc. Second attack. Third, Move.
In more intelligent pokemon, moving may be strategically preferred.

root:
Priority (
    Cond ( isKOed? : ko_self() )
    Cond ( wasSuccessfullyCaught? : caught_display() )
    Cond ( isBeingCaught? : Seq(stunned(), flee()) ) 
    Cond ( enemyInRange? AND NOT lowPP? : Seq(
        chooseAttack() // randomly until I make some *real* ai...
        chooseMotion( Cond ( lowHealth? : flee(), else : MoveTowards[Enemy]()) )
        )
    )
    Cond ( lowPP? : MoveTowards[nearestPPsource]() )
    Cond ( onPlyrTeam AND tooFarFromPlayer? : MoveTowards[Player]() )
    Wander()
)










gm functions to keep/improve:
    - logic.py::TileObstrSensor uses query_tile(tid, 'pkmn_block'/'plyr_block') read
    - logic.py::WildEntSensor uses getTileOccupants(tid) read
    - logic.py::SetPlayerImageCycle accesses (reads) imgs dictionary directly
    - logic.py::State.update_ap queries gm's entities for ease and 
            one-time accesses tile_size.
    - logic.py::logic.plyr_steps reads player's stepsize.
    - logic.py::update reads gm.events user input each cycle

    - abstractEntities.py::Entity needs gm:: uniq_id_counter, entities{} read/write
    - abstractEntities.py::GhostEnt needs image_size field read
    - abstractEntities.py::GhostEnt needs notify_move signaller
    - abstractEntities.py::GhostEnt needs map_x, map_y reads
    - abstractEntities.py::Agent formerly needed get_agent_blocks...

    - agent2.py::Player._init writes to agent_entities, reads hella fields, calls notify_new
    - agent2.py::Player.set_plyr_img directly reads imgs DEP
    - agent2.py::Player.plyr_move DEP called tile query, gm.events reading
    - agent2.py::Player writes to prev_e event frequently, calls notify_move
    - agent2.py::AIAgent calls notify_new, notify_move, accesses imgs, *gm.Plyr*, lists.

    - moves.py::Pokeball._init accesses imgs, tilesize, get_occupants, notify_catching
        
        


OK SO:
- Logic modules apparently implement all actions internally, which out to be maintained
    for consistency. **LAYERED** abstractions can possibly be offloaded to an Agent,
    especially if they do the same actions. In fact, it might make sense to give Agents
    their own reactions to MoveWhere, ChangeImage, Kill/SpawnEnt, or anything that 
    interfaces the gm for resources. 

Where to divide Agent/Logic/State?
--- Logic does not maintain *any* persistent variables. Instead, it maintains 
    the R/W interface for receiving messages, implements various computational 
    objects as the master common 'action' or 'action picker'. Logic takes 
    abstract thoughts, picks among them, and tells the parent Agent what it
    decided. Broadly, this handles anything that changes and interacts with
    other 'things', so as to maintain runtime concurrency consistency.
--- Belt maintains _game_ objects that are accessible and presented to the 
    human player. Methods in it ought to be geared around handling duplicity, 
    numerous stats and stat conversions, and mild speciation/filtering.
--- State maintains _internal_ objects and fields necessary to run the game.
    Inboxed logic messages ought to almost always alter a field. Access is 
    given to Agent and Logic as super-users, and Actions/APs as restricted users.
--- Agent avoids ALL behavior and decision, letting Logic make the decisions. 
    Agents interface with the Game Manager + Pygame global system and, as such,
    send messages to other Agents, are handled as the core of a represented
    (visual) object that is to be manipulated as a collective whole.


?: who updates the global state values? Agent or Logic? I'd say logic.

Components:
    GM and HUD read/write Display.       
    HUD and GM mutually read/write each other, as a combined interface.
    HUDs are only written by designated Belts.
    GM read-writes many Agents.     
    Every Agent can query/message (cp. read/write) any other Agent via GM.
    Agents have up to one Logic, which is necessary for complex action.
    Some Agents, and all with a Logic, have States and Belts (package deal).
    A Logic has a tree of Actions.
    An Agent without a State+Belt+Logic can still have Actions.
    
















